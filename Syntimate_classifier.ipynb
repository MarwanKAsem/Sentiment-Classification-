{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "how do we get the features we use in training?\n",
    "\n",
    "By default we just use every word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(x: str) -> dict[str, float]:\n",
    "    features = {}\n",
    "    x_split = x.split(' ')\n",
    "    for x in x_split:\n",
    "        features[x] = features.get(x, 0) + 1.0\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, initialize the feature weights to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_weights = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reading\n",
    "\n",
    "Read in the data from the training and evaluation  (or finally test) sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xy_data(filename: str) -> tuple[list[str], list[int]]:\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            label, text = line.strip().split(' ||| ')\n",
    "            x_data.append(text)\n",
    "            y_data.append(int(label))\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = read_xy_data(r\"path of your training data\")\n",
    "x_dev, y_dev = read_xy_data(r\"path of your eval data \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal .\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Code\n",
    "so now let's setup the magic our classifier : \n",
    "\n",
    "basically it classifies the labels of our features:\n",
    "\n",
    "Negative will classifiy it as -1\n",
    "\n",
    "Neutral will classifiy it  as  0\n",
    "\n",
    "Positive will classifiy it as  1\n",
    "\n",
    "## How we run the classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifier(features: dict[str, float]) -> int:\n",
    "    score = 0\n",
    "    for feat_name, feat_value in features.items():\n",
    "        score = score + feat_value * feature_weights.get(feat_name, 0)\n",
    "    if score > 0:\n",
    "        return 1\n",
    "    elif score < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Code\n",
    "\n",
    "Learn the weights of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 8544/8544 [00:00<00:00, 83001.85it/s]\n",
      "Epoch 2: 100%|██████████| 8544/8544 [00:00<00:00, 108217.88it/s]\n",
      "Epoch 3: 100%|██████████| 8544/8544 [00:00<00:00, 97151.91it/s]\n",
      "Epoch 4: 100%|██████████| 8544/8544 [00:00<00:00, 111745.92it/s]\n",
      "Epoch 5: 100%|██████████| 8544/8544 [00:00<00:00, 109605.37it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import tqdm\n",
    "NUM_EPOCHS = 5\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    # Shuffle the order of the data\n",
    "    data_ids = list(range(len(x_train)))\n",
    "    random.shuffle(data_ids)\n",
    "    # Run over all data points\n",
    "    for data_id in tqdm.tqdm(data_ids, desc=f'Epoch {epoch}'):\n",
    "        x = x_train[data_id]\n",
    "        y = y_train[data_id]\n",
    "        # We will skip neutral examples\n",
    "        if y == 0:    \n",
    "            continue\n",
    "        # Make a prediction\n",
    "        features = extract_features(x)\n",
    "        predicted_y = run_classifier(features)\n",
    "        # Update the weights if the prediction is wrong\n",
    "        if predicted_y != y:\n",
    "            for feature in features:\n",
    "                feature_weights[feature] = feature_weights.get(feature, 0) + y * features[feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Code\n",
    "\n",
    "How we evaluate the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(x_data: list[str], y_data: list[int]) -> float:\n",
    "    total_number = 0\n",
    "    correct_number = 0\n",
    "    for x, y in zip(x_data, y_data):\n",
    "        y_pred = run_classifier(extract_features(x))\n",
    "        total_number += 1\n",
    "        if y == y_pred:\n",
    "            correct_number += 1\n",
    "    return correct_number / float(total_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 389, 1: 909, -1: 912}\n"
     ]
    }
   ],
   "source": [
    "label_count = {}\n",
    "for y in y_dev:\n",
    "    if y not in label_count:\n",
    "        label_count[y] = 0\n",
    "    label_count[y] += 1\n",
    "print(label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8105102996254682\n",
      "Dev/test accuracy: 0.6321266968325792\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calculate_accuracy(x_train, y_train)\n",
    "test_accuracy = calculate_accuracy(x_dev, y_dev)\n",
    "print(f'Train accuracy: {train_accuracy}')\n",
    "print(f'Dev/test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize feature weights\n",
    "\n",
    "We can inspect the weights that were learned for various features. Below we show the largest, smallest, and randomly selected feature weights. Inspecting them may give insight into the learned classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-k\n",
      "('solid', 19.0)\n",
      "('powerful', 17.0)\n",
      "('half-bad', 17.0)\n",
      "('prose', 17.0)\n",
      "('fast', 16.0)\n",
      "('inventive', 16.0)\n",
      "('appealing', 15.0)\n",
      "('refreshing', 15.0)\n",
      "('remarkable', 14.0)\n",
      "('treat', 14.0)\n",
      "('eyes', 14.0)\n",
      "('Maybe', 14.0)\n",
      "('vividly', 14.0)\n",
      "('rare', 13.0)\n",
      "('manages', 13.0)\n",
      "('sharp', 13.0)\n",
      "('terrific', 13.0)\n",
      "('ability', 13.0)\n",
      "('includes', 13.0)\n",
      "('memorable', 12.0)\n",
      "('fun', 12.0)\n",
      "('buffs', 12.0)\n",
      "('charming', 12.0)\n",
      "('assured', 12.0)\n",
      "('follow', 12.0)\n",
      "\n",
      "Bottom-k\n",
      "('stupid', -21.0)\n",
      "('none', -17.0)\n",
      "('suffers', -16.0)\n",
      "('worst', -15.0)\n",
      "('failure', -15.0)\n",
      "('thinks', -15.0)\n",
      "('TV', -14.0)\n",
      "('pretentious', -14.0)\n",
      "('mess', -14.0)\n",
      "('repetitive', -14.0)\n",
      "('bland', -13.0)\n",
      "('flat', -13.0)\n",
      "('bore', -13.0)\n",
      "('contrived', -13.0)\n",
      "('depress', -13.0)\n",
      "('harder', -13.0)\n",
      "('Lawrence', -13.0)\n",
      "('were', -12.0)\n",
      "('depressing', -12.0)\n",
      "('sticky', -12.0)\n",
      "('alienating', -12.0)\n",
      "('Unfortunately', -12.0)\n",
      "('tired', -12.0)\n",
      "('lacking', -12.0)\n",
      "('lousy', -12.0)\n",
      "\n",
      "Random k\n",
      "('clouds', 2.0)\n",
      "('Orc', 2.0)\n",
      "('ick', -1.0)\n",
      "('Black-and-white', -3.0)\n",
      "('sole', -1.0)\n",
      "('solace', -3.0)\n",
      "('Brings', 4.0)\n",
      "('Hearst', 2.0)\n",
      "('bonus', 3.0)\n",
      "('lucratively', 1.0)\n",
      "('deliciously', 3.0)\n",
      "('year-end', 1.0)\n",
      "('recommend', 4.0)\n",
      "('glorious', 2.0)\n",
      "('Holofcenter', 1.0)\n",
      "('Lifestyle', -2.0)\n",
      "('mush', -1.0)\n",
      "('memorable', 12.0)\n",
      "('Alternates', 4.0)\n",
      "('found', -3.0)\n",
      "('consequences', 0.0)\n",
      "('helluva', 6.0)\n",
      "('Refreshing', 4.0)\n",
      "('servitude', -1.0)\n",
      "('cheesier', -2.0)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "k = 25\n",
    "topk_features = sorted(feature_weights.items(), key=lambda x: -x[1])[:k]\n",
    "bottomk_features = sorted(feature_weights.items(), key=lambda x: x[1])[:k]\n",
    "randomk_features = random.sample(list(feature_weights.items()), k)\n",
    "\n",
    "print(\"Top-k\")\n",
    "for feature in topk_features:\n",
    "    print(feature)\n",
    "\n",
    "print(\"\\nBottom-k\")\n",
    "for feature in bottomk_features:\n",
    "    print(feature)\n",
    "\n",
    "print(\"\\nRandom k\")\n",
    "for feature in randomk_features:\n",
    "    print(feature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
